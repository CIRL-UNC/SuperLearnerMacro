<!DOCTYPE html>
<html>

<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>superlearnerhelp</title>


<style type="text/css">
/**
 * prism.js Twilight theme
 * Based (more or less) on the Twilight theme originally of Textmate fame.
 * @author Remy Bach
 */
code[class*="language-"],
pre[class*="language-"] {
	color: white;
	background: none;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	text-align: left;
	text-shadow: 0 -.1em .2em black;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"],
:not(pre) > code[class*="language-"] {
	background: hsl(0, 0%, 8%); /* #141414 */
}

/* Code blocks */
pre[class*="language-"] {
	border-radius: .5em;
	border: .3em solid hsl(0, 0%, 33%); /* #282A2B */
	box-shadow: 1px 1px .5em black inset;
	margin: .5em 0;
	overflow: auto;
	padding: 1em;
}

pre[class*="language-"]::-moz-selection {
	/* Firefox */
	background: hsl(200, 4%, 16%); /* #282A2B */
}

pre[class*="language-"]::selection {
	/* Safari */
	background: hsl(200, 4%, 16%); /* #282A2B */
}

/* Text Selection colour */
pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: hsla(0, 0%, 93%, 0.15); /* #EDEDED */
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: hsla(0, 0%, 93%, 0.15); /* #EDEDED */
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	border-radius: .3em;
	border: .13em solid hsl(0, 0%, 33%); /* #545454 */
	box-shadow: 1px 1px .3em -.1em black inset;
	padding: .15em .2em .05em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: hsl(0, 0%, 47%); /* #777777 */
}

.token.punctuation {
	opacity: .7;
}

.namespace {
	opacity: .7;
}

.token.tag,
.token.boolean,
.token.number,
.token.deleted {
	color: hsl(14, 58%, 55%); /* #CF6A4C */
}

.token.keyword,
.token.property,
.token.selector,
.token.constant,
.token.symbol,
.token.builtin {
	color: hsl(53, 89%, 79%); /* #F9EE98 */
}

.token.attr-name,
.token.attr-value,
.token.string,
.token.char,
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable,
.token.inserted {
	color: hsl(76, 21%, 52%); /* #8F9D6A */
}

.token.atrule {
	color: hsl(218, 22%, 55%); /* #7587A6 */
}

.token.regex,
.token.important {
	color: hsl(42, 75%, 65%); /* #E9C062 */
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}

pre[data-line] {
	padding: 1em 0 1em 3em;
	position: relative;
}

/* Markup */
.language-markup .token.tag,
.language-markup .token.attr-name,
.language-markup .token.punctuation {
	color: hsl(33, 33%, 52%); /* #AC885B */
}

/* Make the tokens sit above the line highlight so the colours don't look faded. */
.token {
	position: relative;
	z-index: 1;
}

.line-highlight {
	background: -moz-linear-gradient(to right, hsla(0, 0%, 33%, .1) 70%, hsla(0, 0%, 33%, 0)); /* #545454 */
	background: -o-linear-gradient(to right, hsla(0, 0%, 33%, .1) 70%, hsla(0, 0%, 33%, 0)); /* #545454 */
	background: -webkit-linear-gradient(to right, hsla(0, 0%, 33%, .1) 70%, hsla(0, 0%, 33%, 0)); /* #545454 */
	background: hsla(0, 0%, 33%, 0.25); /* #545454 */
	background: linear-gradient(to right, hsla(0, 0%, 33%, .1) 70%, hsla(0, 0%, 33%, 0)); /* #545454 */
	border-bottom: 1px dashed hsl(0, 0%, 33%); /* #545454 */
	border-top: 1px dashed hsl(0, 0%, 33%); /* #545454 */
	left: 0;
	line-height: inherit;
	margin-top: 0.75em; /* Same as .prismâ€™s padding-top */
	padding: inherit 0;
	pointer-events: none;
	position: absolute;
	right: 0;
	white-space: pre;
	z-index: 0;
}

.line-highlight:before,
.line-highlight[data-end]:after {
	background-color: hsl(215, 15%, 59%); /* #8794A6 */
	border-radius: 999px;
	box-shadow: 0 1px white;
	color: hsl(24, 20%, 95%); /* #F5F2F0 */
	content: attr(data-start);
	font: bold 65%/1.5 sans-serif;
	left: .6em;
	min-width: 1em;
	padding: 0 .5em;
	position: absolute;
	text-align: center;
	text-shadow: none;
	top: .4em;
	vertical-align: .3em;
}

.line-highlight[data-end]:after {
	bottom: .4em;
	content: attr(data-end);
	top: auto;
}
</style>


</head>

<body>

<p><link rel="stylesheet" href="/Users/akeil/Library/Application Support/MacDown/Styles/Github2.css"></p>

<h1 id="toc_0">SuperLearnerMacro</h1>

<h3 id="toc_1">Usage details</h3>

<p>The sas script containing the SuperLearner macro actually contains 4 main macros: %SuperLearner, %_SuperLearner, %CVSuperLearner macro, and %_CVSuperLearner</p>

<h4 id="toc_2">0. Installing the macro</h4>

<h5 id="toc_3">Option 1 - run the following two lines in SAS (requires internet connection each SAS session in which super learner is used):</h5>

<div><pre><code class="language-none">FILENAME slgh URL &quot;https://cirl-unc.github.io/SuperLearnerMacro/super_learner_macro.sas&quot;;
%INCLUDE slgh;</code></pre></div>

<h5 id="toc_4">Option 2 - install from release version (requires initial internet connection):</h5>

<ol>
<li>Navigate to the <a href="https://github.com/CIRL-UNC/SuperLearnerMacro/releases">release page of the super learner macro here</a></li>
<li>Download the zip/tar.gz file to your computer and open/unzip the file  - you should see a folder called SuperLearnerMacro-XXXX, where XXXX is the release number</li>
<li>Run the following two lines in SAS (replacing appropriate path names):</li>
</ol>

<p><a href=""></a></p>

<div><pre><code class="language-none">FILENAME slgh &quot;C:/path/to/SuperLearnerMacro-XXXX/super_learner_macro.sas&quot;;
%INCLUDE slgh;</code></pre></div>

<p>Some examples of using the %SuperLearner macro are <a href="https://github.com/CIRL-UNC/SuperLearnerMacro/tree/master/examples">available here</a></p>

<h4 id="toc_5">1. Using %SuperLearner macro</h4>

<p>Stacking is based on what Wolpert refers to as a set of &lsquo;level-0&rsquo; models and a &lsquo;level-1&rsquo; model, indexed by parameters <img src="http://latex.codecogs.com/gif.latex?%5Cmathbf%7B%5Cbeta%7D%5Fm" alt="equation"> and <img src="http://latex.codecogs.com/gif.latex?%5Cmathbf%7B%5Calpha%7D" alt="equation"> in some study sample <em>S</em>. Where</p>

<p>Level-0: <img src="http://latex.codecogs.com/gif.latex?%5Chat%7BY%7D%5F%7Bm%7D%3Df%5Fm%28%5Cmathbf%7Bx%7D%3B%5Cmathbf%7B%5Cbeta%7D%5Fm%2CS%29%5Cmbox%7B%20for%20%7Dm%5Cin1%2C%5Cldots%2CM" alt="equation"></p>

<p>Level-1: <img src="http://latex.codecogs.com/gif.latex?%5Chat%7BY%7D%5F%7Bsl%7D%3Df%5F%7Bsl%7D%28%5Chat%7B%5Cmathbf%7BY%7D%7D%5F%7B%5Cbar%7Bm%7D%7D%3B%5Cmathbf%7B%5Calpha%7D%2CS%29" alt="equation"></p>

<p>The parameterization of the macro is based loosely on this notation. Each level-0 model is referred to as a &lsquo;learner&rsquo; in the super learner library. A call to super learner is structured as follows:</p>

<div><pre><code class="language-none">%SuperLearner(
 Y=,
 X=,
 library=, 
 indata=, 
 preddata=, 
 outdata=sl_out,
 dist=GAUSSIAN,
 method=NNLS
 by=,
 intvars=,
 binary_predictors=,
 ordinal_predictors=,
 nominal_predictors=,
 continuous_predictors=,
 weight=, 
 trtstrat=false, 
 folds=10 
);</code></pre></div>

<p>Macro parameters include the following:</p>

<ul>
<li><p><strong>Y</strong>: [value = variable name] the target variable, or outcome</p></li>
<li><p><strong>X</strong>: [value =   blank, or a space separated list of variable names] predictors of <strong>Y</strong> on the right side of the level-0 models. Note that this is a convenience function for the individual <strong>[coding]_predictors</strong> macro variables. The macro will make a guess at whether each predictor in <strong>X</strong> is continuous, categorical, or binary. (OPTIONAL but at least one of the <strong>X</strong> or <strong>[coding]_predictors</strong> - <strong>binary_predictors</strong>, <strong>ordinal_predictors</strong>, <strong>nominal_predictors</strong>, <strong>continuous_predictors</strong> - parameters must be specified, as described below). If <strong>X</strong> is specified and any one of the <strong>[coding]_predictors</strong> has a value, the macro will generate an error.</p></li>
<li><p><strong>library</strong>: [value =  a space separated list of learners] the names of the <em>m</em> level-0 models (e.g. glm lasso cart). A single learner can be used here if you only wish to know the cross-validated expected loss (e.g. mean-squared error). See <a href="availablelearners.html" title="Available learners">all available default learners here</a> and <a href="newlearners.html" title="Custom learners">how to construct new learners here</a></p></li>
<li><p><strong>indata</strong>: [value = an existing dataset name] the dataset used for analysis that contains <em>Y</em> and all predictors (and weight variables, if needed)</p></li>
<li><p><strong>preddata</strong>: [OPTIONAL value = a dataset name] the validation dataset. A dataset which contains all predictors and possibly <em>Y</em> that is not used in model fitting but predictions for each learner and superlearner are made in these data</p></li>
<li><p><strong>outdata</strong>: [value = a dataset name; default: sl_out] an output dataset that will contain all predictions as well as all variables and observations in the <strong>indata</strong> and <strong>preddata</strong> datasets</p></li>
<li><p><strong>dist</strong>: [value = one of: GAUSSIAN,BERNOULLI; default GAUSSIAN] Super learner can be used to make predictions of a continuous (assumed gaussian in some learners) or a binary variable. Use GAUSSIAN for all continuous variables and BERNOULLI for all binary variables. Nominal/categorical variables currently not supported.</p></li>
<li><p><strong>method</strong>:[value = one of: NNLS,NNLOGLIK,CCLOGLIK,LOGLIK,NNLS,OLS,CCLAE,NNLAE,LAE; default NNLS] the method used to estimate the <img src="http://latex.codecogs.com/gif.latex?%5Cmathbf%7B%5Calpha%7D" alt="equation"> coefficients of the level-1 model.                    Methods are possibly indexed by prefixes: NN, CC, [none], where </p>

<p>NN implies non-negative coefficients that are standardized after fitting to sum to 1. </p>

<p>CC implies a convexity constraint where the super learner fit is subject to a constraint 
that forces the coefficients to fall in [0,1] and sum to 1.0. No prefix implies no 
constraints (which results in some loss of asymptotic properties such as the oracle property).
Note: OLS violates this naming convention, but LS will also be accepted and is equivalent to OLS</p>

<p>LS methods use an L2 loss function (least squares)
LOGLIK methods use a loss function corresponding to the binomial likelihood with a logit link function
LAE methods [experimental] use an L1 loss function (least absolute error), which will not penalize outliers as much as L2 methods, and is also non-differentiable at the minimum
which may cause computational difficulties</p></li>
<li><p><strong>by</strong>: [OPTIONAL value = variable name] a by variable in the usual SAS usage. Separate super learner fits will be specified for each level of the by variable (only one allowed, unlike typical &ldquo;by&rdquo; variables. </p></li>
<li><p><strong>intvars</strong>:[OPTIONAL value = variable name] an intervention variable that is included in the list of predictors. This is a convenience function that will make separate predictions for the intvars variable at 1 or 0 (with all other predictors remaining at their observed levels)</p></li>
<li><p><strong>binary_predictors</strong>: [value =  blank, or a space separated list of variable names] advanced specification of predictors: a space separated list of binary predictors (OPTIONAL but at least one of the <strong>X</strong> or <strong>[coding]_predictors</strong> parameters must be specified)</p></li>
<li><p><strong>ordinal_predictors</strong>: [value =  blank, or a space separated list of variable names]advanced specification of predictors: a space separated list of ordinal predictors (OPTIONAL but at least one of the <strong>X</strong> or <strong>[coding]_predictors</strong> parameters must be specified)</p></li>
<li><p><strong>nominal_predictors</strong>: [value =  blank, or a space separated list of variable names]advanced specification of predictors: a space separated list of nominal predictors (OPTIONAL but at least one of the <strong>X</strong> or <strong>[coding]_predictors</strong> parameters must be specified)</p></li>
<li><p><strong>continuous_predictors</strong>: [value =  blank, or a space separated list of variable names] advanced specification of predictors: a space separated list of continuous predictors (OPTIONAL but at least one of the <strong>X</strong> or <strong>[coding]_predictors</strong> parameters must be specified)</p></li>
<li><p><strong>weight</strong>: [OPTIONAL value = a variable name] a variable containing weights representing the relative contribution of each observation to the fit (a.k.a. case weights). Not all learners will respect non-integer weights, so weights will either be ignored or truncated by some procedures.</p></li>
<li><p><strong>trtstrat</strong>: [value  = true, false; DEFAULT: false] convenience function. If this is set to true and <strong>intvars</strong> is specified, then all fits will be stratified by levels of <strong>intvars</strong> (0,1) accepted only.</p></li>
<li><p><strong>folds</strong>: [value  = integer ; default: 10] number of cross-validation folds to use</p></li>
</ul>

<h4 id="toc_6">2. %_SuperLearner macro</h4>

<p>This is a less user-friendly version of the %SuperLearner macro that may be somewhat faster due to reduced error checking, and offers finer level controls. If the %SuperLearner macro completes successfully, it will give some example code that can be run with %_SuperLearner. Of note, there is no checking of parameter syntax, so the case-sensitive parameter arguments may cause an error in %_SuperLearner, but not %SuperLearner.</p>

<p>One main difference is that %_SuperLearner will make no guesses about variable types for <strong>X</strong>, so use of the <strong>[coding]_predictors</strong> is required for correct specification.</p>

<h4 id="toc_7">3. %CVSuperLearner macro</h4>

<p>This macro is used to estimate the cross-validated expected loss of super learner itself. It does not produce predictions! This gives an idea about whether super learner is the appropriate learner to use in a given scenario, and allows some choice between parameters of the the super learner model, such as the method (e.g. NNLS vs. CCLS).</p>

<ul>
<li><strong>folds</strong>:[value = integer; default: 10] specifies two quantities (which can be individually specified in the %_CVSuperLearner macro):

<ol>
<li><strong>slfolds</strong> number of &ldquo;inner folds&rdquo; (number of folds within each super learner fit) should only be different from <strong>cvslfolds</strong> in odd cases</li>
<li> <strong>cvslfolds</strong>: number of &ldquo;outer folds&rdquo; (the number of folds for cross-validating super learner) should only be different from <strong>slfolds</strong> in odd cases</li>
</ol></li>
</ul>

<p>Options repeated from %SuperLearner</p>

<ul>
<li><strong>Y</strong>: see %SuperLearner macro definition</li>
<li><strong>X</strong>: see %SuperLearner macro definition</li>
<li><strong>by</strong>: see %SuperLearner macro definition</li>
<li><strong>binary_predictors</strong>:  see %SuperLearner macro definition</li>
<li><strong>ordinal_predictors</strong>:  see %SuperLearner macro definition</li>
<li><strong>nominal_predictors</strong>: see %SuperLearner macro definition </li>
<li><strong>continuous_predictors</strong>:  see %SuperLearner macro definition</li>
<li><strong>weight</strong>: see %SuperLearner macro definition</li>
<li><strong>indata</strong>: see %SuperLearner macro definition</li>
<li><strong>dist</strong>: see %SuperLearner macro definition (default: GAUSSIAN)</li>
<li><strong>library</strong>:  see %SuperLearner macro definition </li>
<li><strong>method</strong>:  see %SuperLearner macro definition (default: NNLS)</li>
</ul>

<h4 id="toc_8">4. %_CVSuperLearner macro</h4>

<p>This is a less user-friendly version of the %CVSuperLearner macro that may be somewhat faster due to reduced error checking, and offers finer level controls. See the source code for further tuning options.</p>

<h4 id="toc_9">Further reading</h4>

<h5 id="toc_10">About this macro</h5>

<ol>
<li>A. P. Keil. Super Learning in the SAS system. ArXiv e-prints, May 2018. <a href="https://arxiv.org/abs/1805.08058">https://arxiv.org/abs/1805.08058</a></li>
</ol>

<h5 id="toc_11">About stacking</h5>

<ol>
<li><p>D. H. Wolpert. Stacked generalization. Neural networks, 5(2):241â€“259, 1992.</p></li>
<li><p>L. Breiman. Stacked regressions. Machine learning, 24(1):49â€“64, 1996.</p></li>
</ol>

<h5 id="toc_12">About super learner</h5>

<ol>
<li><p>M. J. van der Laan, E. C. Polley, and A. E. Hubbard. Super learner. Report, Division of Biostatistics, University of California, Berkeley, 2007.</p></li>
<li><p>E. C. Polley and M. J. van der Laan. Super learner in prediction. Report, Division of Biostatistics, University of California, Berkeley, 2010.</p></li>
</ol>

<h4 id="toc_13">Acknowledgements</h4>

<p>This work was only possible with valuable advice and beta testing from the following people: Stephen R Cole, Jessie K Edwards, Katie M O&#39;Brien, Marie Stoner, Jennifer Winston and many others</p>

<p><strong><a href="https://cirl-unc.github.io/SuperLearnerMacro" title="Home">Super learner macro home page</a></strong></p>



<script type="text/javascript">
var _self="undefined"!=typeof window?window:"undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?self:{},Prism=function(){var e=/\blang(?:uage)?-(\w+)\b/i,t=0,n=_self.Prism={util:{encode:function(e){return e instanceof a?new a(e.type,n.util.encode(e.content),e.alias):"Array"===n.util.type(e)?e.map(n.util.encode):e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/\u00a0/g," ")},type:function(e){return Object.prototype.toString.call(e).match(/\[object (\w+)\]/)[1]},objId:function(e){return e.__id||Object.defineProperty(e,"__id",{value:++t}),e.__id},clone:function(e){var t=n.util.type(e);switch(t){case"Object":var a={};for(var r in e)e.hasOwnProperty(r)&&(a[r]=n.util.clone(e[r]));return a;case"Array":return e.map&&e.map(function(e){return n.util.clone(e)})}return e}},languages:{extend:function(e,t){var a=n.util.clone(n.languages[e]);for(var r in t)a[r]=t[r];return a},insertBefore:function(e,t,a,r){r=r||n.languages;var l=r[e];if(2==arguments.length){a=arguments[1];for(var i in a)a.hasOwnProperty(i)&&(l[i]=a[i]);return l}var o={};for(var s in l)if(l.hasOwnProperty(s)){if(s==t)for(var i in a)a.hasOwnProperty(i)&&(o[i]=a[i]);o[s]=l[s]}return n.languages.DFS(n.languages,function(t,n){n===r[e]&&t!=e&&(this[t]=o)}),r[e]=o},DFS:function(e,t,a,r){r=r||{};for(var l in e)e.hasOwnProperty(l)&&(t.call(e,l,e[l],a||l),"Object"!==n.util.type(e[l])||r[n.util.objId(e[l])]?"Array"!==n.util.type(e[l])||r[n.util.objId(e[l])]||(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,l,r)):(r[n.util.objId(e[l])]=!0,n.languages.DFS(e[l],t,null,r)))}},plugins:{},highlightAll:function(e,t){var a={callback:t,selector:'code[class*="language-"], [class*="language-"] code, code[class*="lang-"], [class*="lang-"] code'};n.hooks.run("before-highlightall",a);for(var r,l=a.elements||document.querySelectorAll(a.selector),i=0;r=l[i++];)n.highlightElement(r,e===!0,a.callback)},highlightElement:function(t,a,r){for(var l,i,o=t;o&&!e.test(o.className);)o=o.parentNode;o&&(l=(o.className.match(e)||[,""])[1],i=n.languages[l]),t.className=t.className.replace(e,"").replace(/\s+/g," ")+" language-"+l,o=t.parentNode,/pre/i.test(o.nodeName)&&(o.className=o.className.replace(e,"").replace(/\s+/g," ")+" language-"+l);var s=t.textContent,u={element:t,language:l,grammar:i,code:s};if(!s||!i)return n.hooks.run("complete",u),void 0;if(n.hooks.run("before-highlight",u),a&&_self.Worker){var c=new Worker(n.filename);c.onmessage=function(e){u.highlightedCode=e.data,n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(u.element),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},c.postMessage(JSON.stringify({language:u.language,code:u.code,immediateClose:!0}))}else u.highlightedCode=n.highlight(u.code,u.grammar,u.language),n.hooks.run("before-insert",u),u.element.innerHTML=u.highlightedCode,r&&r.call(t),n.hooks.run("after-highlight",u),n.hooks.run("complete",u)},highlight:function(e,t,r){var l=n.tokenize(e,t);return a.stringify(n.util.encode(l),r)},tokenize:function(e,t){var a=n.Token,r=[e],l=t.rest;if(l){for(var i in l)t[i]=l[i];delete t.rest}e:for(var i in t)if(t.hasOwnProperty(i)&&t[i]){var o=t[i];o="Array"===n.util.type(o)?o:[o];for(var s=0;s<o.length;++s){var u=o[s],c=u.inside,g=!!u.lookbehind,h=!!u.greedy,f=0,d=u.alias;u=u.pattern||u;for(var p=0;p<r.length;p++){var m=r[p];if(r.length>e.length)break e;if(!(m instanceof a)){u.lastIndex=0;var y=u.exec(m),v=1;if(!y&&h&&p!=r.length-1){var b=r[p+1].matchedStr||r[p+1],k=m+b;if(p<r.length-2&&(k+=r[p+2].matchedStr||r[p+2]),u.lastIndex=0,y=u.exec(k),!y)continue;var w=y.index+(g?y[1].length:0);if(w>=m.length)continue;var _=y.index+y[0].length,P=m.length+b.length;if(v=3,P>=_){if(r[p+1].greedy)continue;v=2,k=k.slice(0,P)}m=k}if(y){g&&(f=y[1].length);var w=y.index+f,y=y[0].slice(f),_=w+y.length,S=m.slice(0,w),O=m.slice(_),j=[p,v];S&&j.push(S);var A=new a(i,c?n.tokenize(y,c):y,d,y,h);j.push(A),O&&j.push(O),Array.prototype.splice.apply(r,j)}}}}}return r},hooks:{all:{},add:function(e,t){var a=n.hooks.all;a[e]=a[e]||[],a[e].push(t)},run:function(e,t){var a=n.hooks.all[e];if(a&&a.length)for(var r,l=0;r=a[l++];)r(t)}}},a=n.Token=function(e,t,n,a,r){this.type=e,this.content=t,this.alias=n,this.matchedStr=a||null,this.greedy=!!r};if(a.stringify=function(e,t,r){if("string"==typeof e)return e;if("Array"===n.util.type(e))return e.map(function(n){return a.stringify(n,t,e)}).join("");var l={type:e.type,content:a.stringify(e.content,t,r),tag:"span",classes:["token",e.type],attributes:{},language:t,parent:r};if("comment"==l.type&&(l.attributes.spellcheck="true"),e.alias){var i="Array"===n.util.type(e.alias)?e.alias:[e.alias];Array.prototype.push.apply(l.classes,i)}n.hooks.run("wrap",l);var o="";for(var s in l.attributes)o+=(o?" ":"")+s+'="'+(l.attributes[s]||"")+'"';return"<"+l.tag+' class="'+l.classes.join(" ")+'" '+o+">"+l.content+"</"+l.tag+">"},!_self.document)return _self.addEventListener?(_self.addEventListener("message",function(e){var t=JSON.parse(e.data),a=t.language,r=t.code,l=t.immediateClose;_self.postMessage(n.highlight(r,n.languages[a],a)),l&&_self.close()},!1),_self.Prism):_self.Prism;var r=document.currentScript||[].slice.call(document.getElementsByTagName("script")).pop();return r&&(n.filename=r.src,document.addEventListener&&!r.hasAttribute("data-manual")&&document.addEventListener("DOMContentLoaded",n.highlightAll)),_self.Prism}();"undefined"!=typeof module&&module.exports&&(module.exports=Prism),"undefined"!=typeof global&&(global.Prism=Prism);
</script>

<script type="text/x-mathjax-config">
(function () {

MathJax.Hub.Config({
	'showProcessingMessages': false,
	'messageStyle': 'none'
});

if (typeof MathJaxListener !== 'undefined') {
	MathJax.Hub.Register.StartupHook('End', function () {
		MathJaxListener.invokeCallbackForKey_('End');
	});
}

})();
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


</body>

</html>
